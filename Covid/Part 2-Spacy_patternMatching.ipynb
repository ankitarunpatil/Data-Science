{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"### Code for SpaCy Pattern Matching. The entire code in run on kaggle notebook as the data set was huge and could be easily accessed without download in kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install spacy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## Loading required libraries \nimport os\nimport re\nimport json\nimport math\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport seaborn as sns\n\n\nimport spacy\nfrom spacy.matcher import Matcher\nfrom tqdm import tqdm\n\n## loading pre trained statistical model in English language \nnlp = spacy.load(\"en_core_web_sm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Loading all Json Files \ndebug = False\narticles = {}\nstat = { }\nfor dirpath, subdirs, files in os.walk('/kaggle/input'):\n    for x in files:\n        if x.endswith(\".json\"):\n    \n            articles[x] = os.path.join(dirpath, x)        \ndf = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Defining known terms that are used to refine search of articles \ncovid_reference  = ['covid-19', 'coronavirus', 'cov-2', 'sars-cov-2', 'sars-cov', 'hcov', '2019-ncov']\nrisk_factors = ['diabetes','hypertension','heart disease','cancer','smoking','lung disease','alcohol','climate','small children','age','immune compromised groups','race/ethnicity','mental hospital inpatients','long-term care facility residents','health workers','pregnancy status','chronic kidney disease','Parkinson Disease','Influenza ','pneumonia','Hepatitis B','alcoholic liver disease','fatty liver ','fungal infection','Thyroid diseases','COPD','chronic bronchitis','obesity','BMI','gender','hemoglobin','HDL cholesterol','LDL cholesterol']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Defining patterns that will put together a rule to identify the risk factors  \n\npatterns = {    \n    \"Term Matcher\": lambda term: [{'LOWER': t} for t in term.split(' ')],\n    \"Terms Matcher\": lambda terms: [{\"LOWER\": {\"IN\": terms } }]  \n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### A function to plot dictionary and the risk factors in a bar graph. \ndef create_dict(stat, t = 10, sort_values = False, barh = False, width = 20, height = 4, title = ''):\n    filtered = dict(stat)\n    \n    if sort_values == True:\n       lists = sorted(filtered.items(), key = lambda item : item[1])\n   \n\n    fig = figure(num=None, figsize=(width, height))    #Defining the size and title for bar graph        \n\n    if title != '':\n        fig.suptitle(title, fontsize=20)\n\n    x, y = zip(*lists) \n\n    plt.bar(x, y)\n    plt.show()\n    \n    \n\n\n## A function to count the number of times a risk factor occurrs in articles\ndef risk_counter(res, arg):\n    try:\n        key = str(arg)\n        res.setdefault(key, 0)\n        res[key] = res[key] + 1\n    except:\n        pass\n\n## A function that will help find all thr articles that are related to covid based on the covid_reference terms provided above. \ndef covidMatch(text):\n    return len(re.findall(rf'({\"|\".join(covid_reference)})', text, flags=re.IGNORECASE)) > 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## performing required data pre processing to extract only the abstract and full textbody & articles that have a covid reference in it \nliterature = []\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    sha = str(row['sha'])\n    if sha != 'nan':\n        sha = sha + '.json';\n        try:\n            found = False\n            with open(articles[sha]) as f:\n                data = json.load(f)\n                for key in ['abstract', 'full_text']:\n                    if found == False and key in data:\n                        for content in data[key]:\n                            text = content['text']\n                            if covidMatch(text) == True:                                \n                               literature.append({'file': articles[sha], 'body': text})                                \n        except KeyError:\n            pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## functions to execute pattern matching\n\n## combines all matches and their occurences \ndef result_matches(match_arr, root, sentence, file, index = 0, execution = []):\n    key, result = match_arr[0]\n    rest = match_arr[1:]\n    next_exec = execution + [(key, result, index)]\n    if key in root:\n        rule = root[key]\n        if callable(rule):\n            rule( (result, next_exec, sentence, file) )            \n        else:\n            if 'execute' in rule:\n                rule['execute']( (result, next_exec, sentence, file) )\n            if len(rest) > 0:\n                result_matches(rest, rule, sentence, file, index+1, next_exec)\n\n        \n\ndef merge_matches(matches, doc):\n    match_list = []\n    current = (None, None, None)\n    for match_id, start, end in matches:   \n        if match_id != current[0] or current[2] < start:\n            if current[0] != None:\n                match_list.append(current)\n            current = (match_id, start, end)\n        elif current[2] < end:\n            current = (match_id, current[1], end)\n        \n    match_list.append(current)\n    return match_list;\n\n## calling matcher object and extracts all matching results \ndef match_articles(matcher, doc, rule, file):\n    matches = matcher(doc)\n    if len(matches)>0:\n        to_process = []\n        for match_id, start, end in merge_matches(matches, doc):\n            string_id = nlp.vocab.strings[match_id]  # Get string representation\n            span = doc[start:end]  # The matched span\n            to_process.append((string_id, span))\n        result_matches(to_process, rule['root'], doc, file)\n        \n\n##Converting text articles to document object \ndef parse_articles(matcher, text, rule, file = None, sentence_level = False):\n    text = text.lower()\n    doc = nlp(text)\n    \n    if sentence_level == True:    \n        for sent in doc.sents:\n            sent_doc = nlp(sent.text)\n            match_articles(matcher, sent_doc, rule, file)\n    else:\n        match_articles(matcher, doc, rule, file)\n\n\n## Creating the matcher class object and adding pattern to the matcher object created \ndef extract_words(term, rule, sentence_level = False, literature = literature):\n    matcher = Matcher(nlp.vocab)\n    for name, m in rule[\"Matchers\"]:\n        matcher.add(name, None, m)\n    \n    for article in tqdm(literature):\n        text_list = re.compile(\"\\. \").split(article['body'])\n        file = article['file']\n        for text in text_list:\n            if callable(term):\n                allow = term(text)\n            else:\n                allow = term == None or term in text\n            if allow == True:\n                parse_articles(matcher, text, rule, file, sentence_level) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Matcher rule that searches for risk factors in articles \n## Also uses word risk to search through artilces \n\nstat['risk_factors'] = {}\n\ndef match(text):\n    if covidMatch(text) == True:\n        return len(re.findall(rf'\\ ({\"|\".join(risk_factors)})\\ ', text)) > 0\n    else:\n        return False\n\ndef riskfactor(res):\n    ref, agregate, sentence, file = res\n    risk_counter(stat['risk_factors'], ref.text)\n    \nrule = {    \n    \"Matchers\": [      \n       (\"Risk factors Reference\", patterns['Terms Matcher'](risk_factors)),\n    ],\n    \"root\": {\n        \"Risk factors Reference\": riskfactor\n    }\n}\n        \n\ndef risk_match(text):\n    return len(re.findall(r'risk', text)) > 0\n\nextract_words(risk_match, rule)\ncreate_dict(stat['risk_factors'], 50, True, title = \"Risk Factors\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}